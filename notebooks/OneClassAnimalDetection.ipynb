{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "547df6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shap\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d77341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_recursive(root_dir, label, image_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Recursively loads images from a directory tree, converts them to grayscale,\n",
    "    resizes, and flattens them into a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        root_dir (str): The root directory containing subdirectories with images.\n",
    "        label (int): The label to assign to each image (e.g., 1 for animal).\n",
    "        image_size (tuple): Desired image size as (width, height).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X, y) where X is a NumPy array of shape (N, width*height) containing\n",
    "               the flattened images and y is an array of labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for fname in filenames:\n",
    "            fpath = os.path.join(dirpath, fname)\n",
    "            try:\n",
    "                img = Image.open(fpath).convert(\"L\").resize(image_size)\n",
    "                data.append(np.array(img).flatten())\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping file {fpath} due to error: {e}\")\n",
    "                continue\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b84e37",
   "metadata": {},
   "source": [
    "# One-Class SVM for Animal Detection (When Only Animal Images are Available)\n",
    "\n",
    "This notebook demonstrates how to detect if an image contains an animal, **without** having any non-animal training images. We use a **One-Class SVM**, which learns what “normal” (in this case, *animal*) looks like, and flags anything else as an outlier.\n",
    "\n",
    "## Key Points\n",
    "1. **No non-animal data**: We cannot do a standard supervised (binary) classification. We only have *animal* images.\n",
    "2. **One-Class SVM**: This approach allows us to treat animal images as our \"normal\" class. At prediction time, if a new image deviates significantly from what the model learned, it's flagged as \"Non-Animal.\"\n",
    "3. **Hyperparameter Tuning**: We do a simple grid search over parameters like `nu` and `gamma` to find a good fit for our animal data.\n",
    "4. **Same Function Names**: The required functions are `load_images`, `train_animal_classifier`, and `predict_image`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df26da5",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "We will use:\n",
    "- `PIL` (via `Pillow`) to handle image loading and resizing.\n",
    "- `numpy` for numerical arrays.\n",
    "- `sklearn.svm.OneClassSVM` for our one-class model.\n",
    "- `train_test_split` to create a validation set from our animal images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ad980c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_animal_classifier(animal_path, image_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Trains a One-Class SVM using only animal images. This function expects that\n",
    "    animal_path is a root folder that contains subfolders of images. No non-animal\n",
    "    data is used.\n",
    "\n",
    "    The process includes:\n",
    "      1. Recursively loading animal images.\n",
    "      2. Splitting the data into training (80%) and validation (20%) sets.\n",
    "      3. A manual grid search over a small set of hyperparameters for OneClassSVM.\n",
    "      4. Returning the best model (based on minimal outlier rate on the validation set)\n",
    "         along with the training data for later use as background data in explainability.\n",
    "\n",
    "    Parameters:\n",
    "        animal_path (str): Path to the root folder of animal images (folder-of-folders).\n",
    "        image_size (tuple): Desired image size as (width, height).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (best_model, X_train)\n",
    "    \"\"\"\n",
    "    # Load images recursively from the animal training folder.\n",
    "    X, _ = load_images_recursive(animal_path, label=1, image_size=image_size)\n",
    "    if len(X) == 0:\n",
    "        raise ValueError(f\"No images found in '{animal_path}'. Cannot train the model.\")\n",
    "    print(f\"Loaded {len(X)} animal images.\")\n",
    "\n",
    "    # Split the data into training and validation sets.\n",
    "    X_train, X_val = train_test_split(X, test_size=0.2, random_state=42)\n",
    "    print(f\"Training set size: {len(X_train)} images\")\n",
    "\n",
    "    # Define a grid of hyperparameters for OneClassSVM.\n",
    "    param_grid = {\n",
    "        \"nu\":    [0.001, 0.01, 0.1],   # Controls fraction of outliers.\n",
    "        \"gamma\": [\"scale\", 1e-3, 1e-4]   # Kernel coefficient for RBF.\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_outlier_rate = float(\"inf\")\n",
    "    best_params = None\n",
    "\n",
    "    # Perform a manual grid search over hyperparameters.\n",
    "    for nu_val in param_grid[\"nu\"]:\n",
    "        for gamma_val in param_grid[\"gamma\"]:\n",
    "            print(f\"Training One-Class SVM with nu={nu_val}, gamma={gamma_val}...\", end=\"/r\")\n",
    "            model = OneClassSVM(kernel=\"rbf\", nu=nu_val, gamma=gamma_val)\n",
    "            model.fit(X_train)\n",
    "\n",
    "            # Predict on the validation set: +1 for inliers, -1 for outliers.\n",
    "            val_preds = model.predict(X_val)\n",
    "            outlier_count = np.sum(val_preds == -1)\n",
    "            outlier_rate = outlier_count / len(X_val)\n",
    "\n",
    "            if outlier_rate < best_outlier_rate:\n",
    "                best_outlier_rate = outlier_rate\n",
    "                best_model = model\n",
    "                best_params = (nu_val, gamma_val)\n",
    "\n",
    "    print(f\"Best One-Class SVM params: nu={best_params[0]}, gamma={best_params[1]}\")\n",
    "    print(f\"Validation outlier rate on animal data: {best_outlier_rate:.2%}\")\n",
    "\n",
    "    # Return the best model and training data for later explainability.\n",
    "    return best_model, X_train\n",
    "\n",
    "def predict_image(file_path, model, image_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    Predicts whether an image is 'Animal' or 'Non-Animal' based on the trained OneClassSVM.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the image file.\n",
    "        model (OneClassSVM): Trained OneClassSVM model.\n",
    "        image_size (tuple): Desired image size as (width, height).\n",
    "\n",
    "    Returns:\n",
    "        str: \"Animal\" if the model predicts +1, otherwise \"Non-Animal\".\n",
    "    \"\"\"\n",
    "    img = Image.open(file_path).convert(\"L\").resize(image_size)\n",
    "    arr = np.array(img).flatten().reshape(1, -1)\n",
    "    prediction = model.predict(arr)[0]\n",
    "    return \"Animal\" if prediction == 1 else \"Non-Animal\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1397d",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "Assume you have a folder structure like this:\n",
    "```\n",
    "data/\n",
    "  animals/\n",
    "    animal1.jpg\n",
    "    animal2.jpg\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1ec0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bdb97d5",
   "metadata": {},
   "source": [
    "## How It Works\n",
    "1. **Load & Preprocess**: Converts images to grayscale, resizes them to 64×64, and flattens them into 1D arrays.\n",
    "2. **Train/Validation Split**: Splits the available *animal* images into train (80%) and validation (20%).\n",
    "3. **One-Class SVM**: The model learns a decision boundary around your *animal* data. Anything that deviates significantly is labeled as \"-1\" (outlier).\n",
    "4. **Hyperparameter Tuning**: We do a simple loop over a small grid of `(nu, gamma)` values:\n",
    "   - `nu` controls the fraction of outliers allowed in the training set.\n",
    "   - `gamma` is the kernel coefficient for the RBF kernel.\n",
    "   - We pick the combination that yields the **fewest** outliers on the validation set.\n",
    "5. **Prediction**: `predict_image` loads a new image and runs the trained One-Class SVM. The result is either +1 (\"Animal\") or -1 (\"Non-Animal\").\n",
    "\n",
    "> **Important**: Because we have no real non-animal data for training or testing, we cannot measure the false positive rate (i.e., how often it labels a non-animal as \"Animal\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa5b2fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_image_prediction(file_path, model, background_data, image_size=(128, 128), ns=50):\n",
    "    \"\"\"\n",
    "    Generates a SHAP explanation for a single image prediction made by the OneClassSVM.\n",
    "    It explains the decision function (a score indicating inlier likelihood) for the given image.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the image to be explained.\n",
    "        model (OneClassSVM): Trained OneClassSVM model.\n",
    "        background_data (np.array): A 2D NumPy array of background images (flattened)\n",
    "                                    to be used as a reference for the SHAP explainer.\n",
    "        image_size (tuple): Desired image size as (width, height).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (shap_values, expected_value) for the image.\n",
    "    \"\"\"\n",
    "    img = Image.open(file_path).convert(\"L\").resize(image_size)\n",
    "    instance = np.array(img).flatten().reshape(1, -1)\n",
    "\n",
    "    def model_predict(X):\n",
    "        return model.decision_function(X)\n",
    "\n",
    "    # Create a KernelExplainer using the provided background data.\n",
    "    explainer = shap.KernelExplainer(model_predict, background_data)\n",
    "    shap_values = explainer.shap_values(instance, nsamples=ns)\n",
    "    expected_value = explainer.expected_value\n",
    "\n",
    "    return shap_values, expected_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ac7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b28e2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_images_dir = r\"C:\\Users\\rf4thyrvm\\Documents\\CritterSnap\\data\\example\\as_conservationistFrankfurt\\IE_Forest_County_Wicklow_21_loc_01-20241031T145429Z-001\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fa3efd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_animal_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimal_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m, in \u001b[0;36mtrain_animal_classifier\u001b[1;34m(animal_path, image_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTrains a One-Class SVM using only animal images. This function expects that\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03manimal_path is a root folder that contains subfolders of images. No non-animal\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    tuple: (best_model, X_train)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Load images recursively from the animal training folder.\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m X, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manimal_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Cannot train the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 21\u001b[0m, in \u001b[0;36mload_images_recursive\u001b[1;34m(root_dir, label, image_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, fname)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(img)\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m     23\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "File \u001b[1;32mc:\\Users\\rf4thyrvm\\Documents\\CritterSnap\\.venv\\Lib\\site-packages\\PIL\\Image.py:2365\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2353\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2354\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2355\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[0;32m   2356\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2357\u001b[0m         )\n\u001b[0;32m   2358\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2359\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2360\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2361\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2362\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2363\u001b[0m         )\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, X_train = train_animal_classifier(animal_images_dir, image_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6177f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image_path = r\"C:\\Users\\rf4thyrvm\\Documents\\CritterSnap\\data\\example\\ds_researchATU\\IMG_0197.JPG\"\n",
    "test_image_path = r\"C:\\Users\\rf4thyrvm\\Documents\\CritterSnap\\data\\example\\ds_researchATU\\IMG_0001.JPG\"\n",
    "prediction = predict_image(test_image_path, model, image_size=(64, 64))\n",
    "print(f\"Prediction for {test_image_path}: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8f819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
